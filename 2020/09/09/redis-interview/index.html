

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/logo.jpg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="ifknow">
  <meta name="keywords" content="SpringBoot,SpringCloud,MyBatis,Nginx,Linux,Java,JavaWeb,">
  <title>Redis面试全攻略、面试题大集合 - ifknow | 分享技术·享受生活</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/a11y-dark.min.css" />
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_6peoq002giu.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
      href="/">&nbsp;<strong>ifknow</strong>&nbsp;</a>
    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
      data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
      aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
        
        
        
        
        <li class="nav-item">
          <a class="nav-link" href="/">
            <i class="iconfont icon-home-fill"></i>
            首页
          </a>
        </li>
        
        
        
        
        
        
        <li class="nav-item">
          <a class="nav-link" href="/categories/">
            <i class="iconfont icon-category-fill"></i>
            分类
          </a>
        </li>
        
        
        
        
        
        
        <li class="nav-item">
          <a class="nav-link" href="/archives/">
            <i class="iconfont icon-archive-fill"></i>
            归档
          </a>
        </li>
        
        
        
        
        
        
        <li class="nav-item">
          <a class="nav-link" href="/tags/">
            <i class="iconfont icon-tags-fill"></i>
            标签
          </a>
        </li>
        
        
        
        
        
        
        <li class="nav-item">
          <a class="nav-link" href="/about/">
            <i class="iconfont icon-user-fill"></i>
            关于
          </a>
        </li>
        
        
        
        
        
        
        <li class="nav-item">
          <a class="nav-link" href="/links/">
            <i class="iconfont icon-link-fill"></i>
            友链
          </a>
        </li>
        
        
        
        <li class="nav-item" id="search-btn">
          <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
              class="iconfont icon-search"></i>&nbsp;</a>
        </li>
        
        
        <li class="nav-item" id="color-toggle-btn">
          <a class="nav-link" href="javascript:">&nbsp;<i class="iconfont icon-dark"
              id="color-toggle-icon"></i>&nbsp;</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>
    <div class="banner intro-2" id="background" parallax=true
         style="background: url('https://gulimall-gsy.oss-cn-hangzhou.aliyuncs.com/blog/posts.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-09-09 14:00" pubdate>
      2020-09-09 星期三 02:00:48 下午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      12.2k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      142
       分钟
    </span>
  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-post-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-post-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">Redis面试全攻略、面试题大集合</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2020-09-09 星期三 02:09:34 下午
                
              </p>
            
            <div class="markdown-body" id="post-body">
              <blockquote>
<p>本文转载自 <strong>后端技术指南针</strong> 微信公众号。</p>
</blockquote>
<h1 id="0-前言"><a href="#0-前言" class="headerlink" title="0.前言"></a>0.前言</h1><p> 通过本文你将了解到以下内容： </p>
<ul>
<li>Redis的作者、发展演进和江湖地位</li>
<li>Redis面试问题的概况</li>
<li>Redis底层实现相关的问题包括：<br> . <strong>常用数据类型底层实现、SDS的原理和优势、字典的实现原理、跳表和有序集合的原理、Redis的线程模式和服务模型</strong></li>
</ul>
<p><code>温馨提示：</code>内容并不难，就怕你不看。</p>
<p>看不懂可以先收藏先Mark，等到深入研究的时间再翻出来看看，你就发现真是24K干货呀！停止吹嘘，写点不一样的文字吧！</p>
<h1 id="1-Redis往事"><a href="#1-Redis往事" class="headerlink" title="1.Redis往事"></a>1.Redis往事</h1><p>Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久化的高性能键值对数据库。Redis的之父是来自意大利的西西里岛的Salvatore Sanfilippo，Github网名antirez，笔者找了作者的一些简要信息并翻译了一下，如图：<br><img src="https://img-blog.csdnimg.cn/20200727103242732.png#pic_center" srcset="/img/loading.gif" alt="Salvatore Sanfilippo 简介"><br>从2009年第一个版本起Redis已经走过了10个年头，目前Redis仍然是最流行的key-value型内存数据库的之一。</p>
<p>优秀的开源项目离不开大公司的支持，在2013年5月之前，其开发由<strong>VMware</strong>赞助，而2013年5月至2015年6月期间，其开发由<strong>毕威拓</strong>赞助，从2015年6月开始，Redis的开发由<strong>Redis Labs</strong>赞助。</p>
<p><img src="https://img-blog.csdnimg.cn/20200727103446276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>笔者也使用过一些其他的NoSQL，有的支持的value类型非常单一，因此很多操作都必须在客户端实现，比如value是一个结构化的数据，需要修改其中某个字段就需要整体读出来修改再整体写入，显得很笨重，但是Redis的value支持多种类型，实现了很多操作在服务端就可以完成了，这个对客户端而言非常方便。</p>
<p>当然Redis由于是内存型的数据库，数据量存储量有限而且分布式集群成本也会非常高，因此有很多公司开发了基于SSD的类Redis系统，比如<code>360开发的SSDB、Pika等数据库</code>，但是笔者认为从<code>0到1的难度是大于从1到2的难度</code>的，毋庸置疑Redis是NoSQL中浓墨重彩的一笔，值得我们去深入研究和使用。</p>
<h1 id="2-Redis的江湖地位"><a href="#2-Redis的江湖地位" class="headerlink" title="2.Redis的江湖地位"></a>2.Redis的江湖地位</h1><p>Redis提供了Java、C/C++、C#、 PHP 、JavaScript、 Perl 、Object-C、Python、Ruby、Erlang、Golang等<code>多种主流语言的客户端</code>，因此无论使用者是什么语言栈总会找到属于自己的那款客户端，受众非常广。</p>
<p>笔者查了datanyze.com网站看了下Redis和MySQL的<code>最新市场份额和排名</code>对比以及<code>全球Top站点的部署量&lt;/font&gt;对比(网站数据更新到写作当日2019.12.11)： ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103923668.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center) 可以看到</code>Redis总体份额排名第9并且在全球Top100站点中部署数量与MySQL基本持平``，所以Redis还是有一定的江湖地位的。</p>
<h1 id="3-聊聊实战"><a href="#3-聊聊实战" class="headerlink" title="3.聊聊实战"></a>3.聊聊实战</h1><p>目前Redis发布的稳定版本已经到了5.x（截止当前时间，稳定版本已经到了6.0.6）<br><img src="https://img-blog.csdnimg.cn/20200727104200755.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>功能也越来越强大，从国内外互联网公司来看Redis几乎是<code>标配</code>了。作为开发人员在日常笔试面试和工作中遇到Redis相关问题的概率非常大，掌握Redis的相关知识点都十分有必要。</p>
<p><code>学习和梳理一个复杂的东西肯定不能胡子眉毛一把抓</code>，每个人都有自己的认知思路，笔者认为要从充分掌握Redis需要<code>从底向上、从外到内</code>去理解Redis。</p>
<p>Redis的实战知识点可以简单分为<code>三个层次</code>：</p>
<ul>
<li><code>底层实现</code>：主要是从Redis的源码中提炼的问题，包括但不限于底层数据结构、服务模型、算法设计等。</li>
<li><code>基础架构</code>：可用概况为Redis整体对外的功能点和表现，包括但不限于单机版主从架构实现、主从数据同步、哨兵机制、集群实现、分布式一致性、故障迁移等。</li>
<li><code>实际应用</code>：实战中Redis可用帮你做什么，包括但不限于单机缓存、分布式缓存、分布式锁、一些应用。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200727104557708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<h1 id="4-底层实现热点题目"><a href="#4-底层实现热点题目" class="headerlink" title="4.底层实现热点题目"></a>4.底层实现热点题目</h1><p>底层实现篇的题目主要是与Redis的源码和设计相关，可以说是Redis功能的基石，了解底层实现可以让我们更好地掌握功能，由于底层代码很多，在后续的基础架构篇中仍然会穿插源码来分析，因此本篇只列举一些热点的问题。</p>
<h2 id="Q1-Redis常用五种数据类型是如何实现的？"><a href="#Q1-Redis常用五种数据类型是如何实现的？" class="headerlink" title="Q1: Redis常用五种数据类型是如何实现的？"></a>Q1: Redis常用五种数据类型是如何实现的？</h2><p>Redis支持的常用5种数据类型指的是value类型，分别为：<strong>字符串String、列表List、哈希Hash、集合Set、有序集合Zset</strong>，但是Redis后续又丰富了几种数据类型分别是Bitmaps、HyperLogLogs、GEO。</p>
<p>由于Redis是基于标准C写的，只有最基础的数据类型，因此Redis为了满足对外使用的5种数据类型，开发了属于自己<strong>独有的一套基础数据结构</strong>，使用这些数据结构来实现5种数据类型。</p>
<p>Redis底层的数据结构包括：简单动态数组SDS、链表、字典、跳跃链表、整数集合、压缩列表、对象。</p>
<p>Redis为了<strong>平衡空间和时间效率</strong>，针对value的具体类型在底层<strong>会采用不同的数据结构来实现</strong>，其中哈希表和压缩列表是复用比较多的数据结构，如下图展示了对外数据类型和底层数据结构之间的映射关系：</p>
<p><img src="https://img-blog.csdnimg.cn/20200727104836150.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>从图中可以看到<strong>ziplist压缩列表</strong>可以作为Zset、Set、List三种数据类型的底层实现，看来很强大，压缩列表是一种为了<strong>节约内存而开发的且经过特殊编码之后的连续内存块顺序型数据结构</strong>，底层结构还是比较复杂的。</p>
<h2 id="Q2-Redis的SDS和C中字符串相比有什么优势？"><a href="#Q2-Redis的SDS和C中字符串相比有什么优势？" class="headerlink" title="Q2: Redis的SDS和C中字符串相比有什么优势？"></a>Q2: Redis的SDS和C中字符串相比有什么优势？</h2><p>在C语言中使用N+1长度的字符数组来表示字符串，尾部使用<code>&#39;\0&#39;</code>作为结尾标志，对于此种实现<strong>无法满足Redis对于安全性、效率、丰富的功能的要求</strong>，因此Redis单独封装了SDS简单动态字符串结构。</p>
<p>在理解SDS的优势之前需要先看下SDS的<strong>实现细节</strong>，找了github最新的src/sds.h的定义看下：</p>
<div class="hljs"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">char</span> *sds;

<span class="hljs-comment">/*这个用不到 忽略即可*/</span>
<span class="hljs-class"><span class="hljs-keyword">struct</span> __<span class="hljs-title">attribute__</span> ((__<span class="hljs-title">packed__</span>)) <span class="hljs-title">sdshdr5</span> &#123;</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> flags; <span class="hljs-comment">/* 3 lsb of type, and 5 msb of string length */</span>
    <span class="hljs-keyword">char</span> buf[];
&#125;;

<span class="hljs-comment">/*不同长度的header 8 16 32 64共4种 都给出了四个成员</span>
<span class="hljs-comment">len：当前使用的空间大小；alloc去掉header和结尾空字符的最大空间大小</span>
<span class="hljs-comment">flags:8位的标记 下面关于SDS_TYPE_x的宏定义只有5种 3bit足够了 5bit没有用</span>
<span class="hljs-comment">buf:这个跟C语言中的字符数组是一样的，从typedef char* sds可以知道就是这样的。</span>
<span class="hljs-comment">buf的最大长度是2^n 其中n为sdshdr的类型，如当选择sdshdr16，buf_max=2^16。</span>
<span class="hljs-comment">*/</span>
<span class="hljs-class"><span class="hljs-keyword">struct</span> __<span class="hljs-title">attribute__</span> ((__<span class="hljs-title">packed__</span>)) <span class="hljs-title">sdshdr8</span> &#123;</span>
    <span class="hljs-keyword">uint8_t</span> len; <span class="hljs-comment">/* used */</span>
    <span class="hljs-keyword">uint8_t</span> alloc; <span class="hljs-comment">/* excluding the header and null terminator */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> flags; <span class="hljs-comment">/* 3 lsb of type, 5 unused bits */</span>
    <span class="hljs-keyword">char</span> buf[];
&#125;;
<span class="hljs-class"><span class="hljs-keyword">struct</span> __<span class="hljs-title">attribute__</span> ((__<span class="hljs-title">packed__</span>)) <span class="hljs-title">sdshdr16</span> &#123;</span>
    <span class="hljs-keyword">uint16_t</span> len; <span class="hljs-comment">/* used */</span>
    <span class="hljs-keyword">uint16_t</span> alloc; <span class="hljs-comment">/* excluding the header and null terminator */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> flags; <span class="hljs-comment">/* 3 lsb of type, 5 unused bits */</span>
    <span class="hljs-keyword">char</span> buf[];
&#125;;
<span class="hljs-class"><span class="hljs-keyword">struct</span> __<span class="hljs-title">attribute__</span> ((__<span class="hljs-title">packed__</span>)) <span class="hljs-title">sdshdr32</span> &#123;</span>
    <span class="hljs-keyword">uint32_t</span> len; <span class="hljs-comment">/* used */</span>
    <span class="hljs-keyword">uint32_t</span> alloc; <span class="hljs-comment">/* excluding the header and null terminator */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> flags; <span class="hljs-comment">/* 3 lsb of type, 5 unused bits */</span>
    <span class="hljs-keyword">char</span> buf[];
&#125;;
<span class="hljs-class"><span class="hljs-keyword">struct</span> __<span class="hljs-title">attribute__</span> ((__<span class="hljs-title">packed__</span>)) <span class="hljs-title">sdshdr64</span> &#123;</span>
    <span class="hljs-keyword">uint64_t</span> len; <span class="hljs-comment">/* used */</span>
    <span class="hljs-keyword">uint64_t</span> alloc; <span class="hljs-comment">/* excluding the header and null terminator */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> flags; <span class="hljs-comment">/* 3 lsb of type, 5 unused bits */</span>
    <span class="hljs-keyword">char</span> buf[];
&#125;;

<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> SDS_TYPE_5  0</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> SDS_TYPE_8  1</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> SDS_TYPE_16 2</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> SDS_TYPE_32 3</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> SDS_TYPE_64 4</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> SDS_TYPE_MASK 7</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> SDS_TYPE_BITS 3</span></code></pre></div>

<p>看了前面的定义，笔者画了个图：<br><img src="https://img-blog.csdnimg.cn/20200727105100555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p>从图中可以知道sds本质分为三部分：header、buf、null结尾符，其中header可以认为是整个sds的指引部分，给定了使用的空间大小、最大分配大小等信息，再用一张网上的图来清晰看下sdshdr8的实例：<br><img src="https://img-blog.csdnimg.cn/20200727105141794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p>在sds.h/sds.c源码中可清楚地看到sds完整的实现细节，本文就不展开了要不然篇幅就过长了，快速进入主题说下<strong>sds的优势</strong>：</p>
<ul>
<li><p><strong>O(1)获取长度</strong>: C字符串需要遍历而sds中有len可以直接获得；</p>
</li>
<li><p><strong>防止缓冲区溢出bufferoverflow</strong>:<br>当sds需要对字符串进行修改时，首先借助于len和alloc检查空间是否满足修改所需的要求，如果空间不够的话，SDS会<code>自动扩展空间</code>，避免了像C字符串操作中的覆盖情况；</p>
</li>
<li><p><strong>有效降低内存分配次数</strong>：C字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配、sds使用了<code>空间预分配和惰性空间释放</code>机制，说白了就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给OS，这两个机制也是比较好理解的；</p>
</li>
<li><p><strong>二进制安全</strong>：C语言字符串只能保存ascii码，对于图片、音频等信息无法保存，sds是二进制安全的，写入什么读取就是什么，不做任何过滤和限制；</p>
</li>
</ul>
<p>老规矩上一张黄健宏大神总结好的图：<br><img src="https://img-blog.csdnimg.cn/20200727105420771.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<h2 id="Q3-Redis的字典是如何实现的？简述渐进式rehash的过程。"><a href="#Q3-Redis的字典是如何实现的？简述渐进式rehash的过程。" class="headerlink" title="Q3:Redis的字典是如何实现的？简述渐进式rehash的过程。"></a>Q3:Redis的字典是如何实现的？简述渐进式rehash的过程。</h2><p>字典算是Redis5中常用数据类型中的明星成员了，前面说过字典可以基于ziplist和hashtable来实现，我们只讨论基于<strong>hashtable实现</strong>的原理。</p>
<p>字典是个<strong>层次非常明显的数据类型</strong>，如图：<br><img src="https://img-blog.csdnimg.cn/20200727105515993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>有了个大概的概念，我们看下最新的src/dict.h<strong>源码定义</strong>：</p>
<div class="hljs"><pre><code class="hljs c"><span class="hljs-comment">//哈希节点结构</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span> &#123;</span>
    <span class="hljs-keyword">void</span> *key;
    <span class="hljs-keyword">union</span> &#123;
        <span class="hljs-keyword">void</span> *val;
        <span class="hljs-keyword">uint64_t</span> u64;
        <span class="hljs-keyword">int64_t</span> s64;
        <span class="hljs-keyword">double</span> d;
    &#125; v;
    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span> *<span class="hljs-title">next</span>;</span>
&#125; dictEntry;

<span class="hljs-comment">//封装的是字典的操作函数指针</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictType</span> &#123;</span>
    <span class="hljs-keyword">uint64_t</span> (*hashFunction)(<span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span> *key);
    <span class="hljs-keyword">void</span> *(*keyDup)(<span class="hljs-keyword">void</span> *privdata, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span> *key);
    <span class="hljs-keyword">void</span> *(*valDup)(<span class="hljs-keyword">void</span> *privdata, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span> *obj);
    <span class="hljs-keyword">int</span> (*keyCompare)(<span class="hljs-keyword">void</span> *privdata, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span> *key1, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span> *key2);
    <span class="hljs-keyword">void</span> (*keyDestructor)(<span class="hljs-keyword">void</span> *privdata, <span class="hljs-keyword">void</span> *key);
    <span class="hljs-keyword">void</span> (*valDestructor)(<span class="hljs-keyword">void</span> *privdata, <span class="hljs-keyword">void</span> *obj);
&#125; dictType;

<span class="hljs-comment">/* This is our hash table structure. Every dictionary has two of this as we</span>
<span class="hljs-comment"> * implement incremental rehashing, for the old to the new table. */</span>
<span class="hljs-comment">//哈希表结构 该部分是理解字典的关键</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictht</span> &#123;</span>
    dictEntry **table;
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> size;
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> sizemask;
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> used;
&#125; dictht;

<span class="hljs-comment">//字典结构</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dict</span> &#123;</span>
    dictType *type;
    <span class="hljs-keyword">void</span> *privdata;
    dictht ht[<span class="hljs-number">2</span>];
    <span class="hljs-keyword">long</span> rehashidx; <span class="hljs-comment">/* rehashing not in progress if rehashidx == -1 */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> iterators; <span class="hljs-comment">/* number of iterators currently running */</span>
&#125; dict;</code></pre></div>

<p>C语言的好处在于定义必须是由最底层向外的，因此我们可以看到一个明显的层次变化，于是笔者又画一图来展现具体的<code>层次</code>概念：<br><img src="https://img-blog.csdnimg.cn/20200727105613601.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<ul>
<li>关于dictEntry</li>
</ul>
<p>dictEntry是哈希表节点，也就是我们存储数据地方，其保护的成员有：key,v,next指针。key保存着键值对中的键，v保存着键值对中的值，值可以是一个指针或者是uint64_t或者是int64_t。next是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来<strong>解决哈希冲突</strong>的问题。</p>
<p>如图为两个冲突的哈希节点的连接关系：<br><img src="https://img-blog.csdnimg.cn/20200727105706611.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<ul>
<li>关于dictht</li>
</ul>
<p>从源码看哈希表包括的成员有table、size、used、sizemask。table是一个数组，数组中的每个元素都是一个指向dictEntry结构的指针， 每个dictEntry结构保存着一个键值对；size 属性记录了哈希表table的大小，而used属性则记录了哈希表目前已有节点的数量。sizemask等于size-1和哈希值计算一个键在table数组的索引，也就是计算index时用到的。<br><img src="https://img-blog.csdnimg.cn/20200727105753158.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>如上图展示了一个大小为4的table中的哈希节点情况，其中k1和k0在index=2发生了哈希冲突，进行开链表存在，本质上是先存储的k0，<code>k1放置是发生冲突为了保证效率直接放在冲突链表的最前面，因为该链表没有尾指针</code>。</p>
<ul>
<li>关于dict</li>
</ul>
<p>从源码中看到dict结构体就是字典的定义，包含的成员有type，privdata、ht、rehashidx。其中dictType指针类型的type指向了操作字典的api，理解为函数指针即可，<code>ht是包含2个dictht的数组</code>，也就是字典包含了2个哈希表，rehashidx进行rehash时使用的变量，privdata配合</p>
<p><img src="https://img-blog.csdnimg.cn/20200727105809212.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<ul>
<li>字典的哈希算法</li>
</ul>
<div class="hljs"><pre><code class="hljs c"><span class="hljs-comment">//伪码：使用哈希函数，计算键key的哈希值</span>
hash = dict-&gt;type-&gt;hashFunction(key);
<span class="hljs-comment">//伪码：使用哈希表的sizemask和哈希值，计算出在ht[0]或许ht[1]的索引值</span>
index = hash &amp; dict-&gt;ht[x].sizemask;
<span class="hljs-comment">//源码定义</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)</span></code></pre></div>

<p>redis使用MurmurHash算法计算哈希值，该算法最初由Austin Appleby在2008年发明，MurmurHash算法的无论数据输入情况如何都可以给出随机分布性较好的哈希值并且计算速度非常快，目前有MurmurHash2和MurmurHash3等版本。</p>
<ul>
<li>普通Rehash重新散列</li>
</ul>
<p>哈希表保存的键值对数量是<strong>动态变化</strong>的，为了让哈希表的负载因子维持在一个合理的范围之内，就需要对哈希表进行扩缩容。</p>
<p>扩缩容是通过执行rehash重新散列来完成，对字典的哈希表<code>执行普通rehash的基本步骤为分配空间-&gt;逐个迁移-&gt;交换哈希表</code>，详细过程如下：</p>
<ol>
<li>为字典的ht[1]哈希表分配空间，分配的空间大小取决于要执行的操作以及ht[0]当前包含的键值对数量：<br>扩展操作时ht[1]的大小为第一个大于等于ht[0].used*2的2^n；<br> 收缩操作时ht[1]的大小为第一个大于等于ht[0].used的2^n ；<br> <strong>扩展时比如h[0].used=200，那么需要选择大于400的第一个2的幂，也就是2^9=512。</strong></li>
<li>将保存在ht[0]中的所有键值对重新计算键的哈希值和索引值rehash到ht[1]上；</li>
<li>重复rehash直到ht[0]包含的所有键值对全部迁移到了ht[1]之后释放 ht[0]， 将ht[1]设置为 ht[0]，并在ht[1]新创建一个空白哈希表， 为下一次rehash做准备。</li>
</ol>
<ul>
<li>渐进Rehash过程</li>
</ul>
<p>Redis的rehash动作<strong>并不是一次性完成的，而是分多次、渐进式地完成的</strong>，原因在于当哈希表里保存的键值对数量很大时， 一次性将这些键值对全部rehash到ht[1]可能会<strong>导致服务器在一段时间内停止服务</strong>，这个是无法接受的。</p>
<p>针对这种情况Redis采用了<strong>渐进式rehash</strong>，过程的详细步骤：</p>
<ol>
<li>为ht[1]分配空间，这个过程和普通Rehash没有区别；</li>
<li>将rehashidx设置为0，表示rehash工作正式开始，同时这个rehashidx是递增的，从0开始表示从数组第一个元素开始rehash。</li>
<li>在rehash进行期间，每次对<strong>字典执行增删改查操作</strong>时，<code>顺带</code>将ht[0]哈希表在rehashidx索引上的键值对rehash到 ht[1]，完成后将rehashidx加1，指向下一个需要rehash的键值对。</li>
<li>随着字典操作的不断执行，最终ht[0]的所有键值对都会被rehash至ht[1]，再将rehashidx属性的值设为-1来表示 rehash操作已完成。</li>
</ol>
<p>渐进式 rehash的思想在于<strong>将rehash键值对所需的计算工作分散到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的阻塞问题。</strong></p>
<p>看到这里不禁去想这种<strong>捎带脚式</strong>的rehash会不会*<em>导致整个过程非常漫长**</em>？如果某个value一直没有操作那么需要扩容时由于一直不用所以影响不大，需要缩容时如果一直不处理可能造成内存浪费，具体的还没来得及研究，<strong>先埋个问题吧！</strong></p>
<h2 id="Q4-跳跃链表了解吗？Redis的Zset如何使用跳表实现的？"><a href="#Q4-跳跃链表了解吗？Redis的Zset如何使用跳表实现的？" class="headerlink" title="Q4:跳跃链表了解吗？Redis的Zset如何使用跳表实现的？"></a>Q4:跳跃链表了解吗？Redis的Zset如何使用跳表实现的？</h2><p>ZSet这种数据类型也非常有用，在做排行榜需求时非常有用，笔者就曾经使用这种数据类型来实现某日活2000w的app的排行榜，所以了解下ZSet的底层实现很有必要，之前笔者写过两篇文章介绍跳跃链表和ZSet的实现，因此查阅即可。<br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMTI2Ng==&mid=2247483919&idx=1&sn=1b62c9a125be1bed7970aae906639d21&scene=21#wechat_redirect">深入理解跳跃链表[一]</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMTI2Ng==&mid=2247483948&idx=1&sn=83c1ef41690a60d0b70fa4374d6e64b8&scene=21#wechat_redirect">深入理解跳表在Redis中的应用</a></p>
<h2 id="Q5-Redis为什么使用单线程？讲讲Redis网络模型以及单线程如何协调各种事件运行起来的？"><a href="#Q5-Redis为什么使用单线程？讲讲Redis网络模型以及单线程如何协调各种事件运行起来的？" class="headerlink" title="Q5:Redis为什么使用单线程？讲讲Redis网络模型以及单线程如何协调各种事件运行起来的？"></a>Q5:Redis为什么使用单线程？讲讲Redis网络模型以及单线程如何协调各种事件运行起来的？</h2><p>Redis在新版本中并不是单纯的单线程服务，一些辅助工作会有BIO后台线程来完成，并且Redis底层使用epoll来实现了基于事件驱动的反应堆模式，在整个主线程运行工程中不断协调时间事件和文件事件来完成整个系统的运行，笔者之前写过两篇相关的文章，查阅即可得到更深层次的答案。<br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMTI2Ng==&mid=2247483755&idx=1&sn=20496502810f53409b1274afcc76a997&scene=21#wechat_redirect">理解Redis单线程运行模式</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMTI2Ng==&mid=2247483747&idx=1&sn=184f86ec27472736f9d0f808b54fe753&scene=21#wechat_redirect">理解Redis的反应堆模式</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMTI2Ng==&mid=2247483717&idx=1&sn=dfa5cafa7695f2d0dfb8bc51b414d46b&scene=21#wechat_redirect">浅析Redis 4.0新特性之LazyFree</a></p>
<h2 id="Q6-了解Redis的内存回收吗？讲讲你的理解"><a href="#Q6-了解Redis的内存回收吗？讲讲你的理解" class="headerlink" title="Q6:了解Redis的内存回收吗？讲讲你的理解"></a>Q6:了解Redis的内存回收吗？讲讲你的理解</h2><h3 id="1-1-为什么要回收内存？"><a href="#1-1-为什么要回收内存？" class="headerlink" title="1.1 为什么要回收内存？"></a>1.1 为什么要回收内存？</h3><p>Redis作为内存型数据库，如果单纯的只进不出早晚就<strong>撑爆</strong>了，事实上很多把Redis当做主存储DB用的家伙们早晚会尝到这个<strong>苦果</strong>，当然除非你家厂子确实<strong>不差钱</strong>，数T级别的内存都<strong>毛毛雨</strong>，或者数据增长一定程度之后不再增长的场景，就另当别论了。</p>
<p>对于我们这种把节约成本当做<strong>KPI</strong>的普通厂子，还是把Redis当<strong>缓存</strong>用比较符合家里的经济条件，所以这么看面试官的问题还算是比较贴合实际，比起那些<strong>手撕RBTree</strong>好一些，如果问题刚好在你知识射程范围内，先给面试官<strong>点个赞</strong>再说！</p>
<p>为了让Redis服务<strong>安全稳定</strong>的运行，让使用内存保持在一定的<strong>阈值内</strong>是非常有必要的，因此我们就需要删除该删除的，清理该清理的，把内存留给需要的键值对，试想一条大河需要设置几个<strong>警戒水位来确保不决堤不枯竭</strong>，Redis也是一样的，只不过Redis只关心决堤即可，来一张图：<br><img src="https://img-blog.csdnimg.cn/20200727111416193.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>图中设定机器内存为128GB，占用64GB算是比较安全的水平，如果内存接近80%也就是100GB左右，那么认为Redis目前承载能力已经比较大了，具体的比例可以根据公司和个人的业务经验来确定。</p>
<p>笔者只是想表达出于<strong>安全和稳定的考虑</strong>，不要觉得128GB的内存就意味着存储128GB的数据，都是要<strong>打折</strong>的。</p>
<h3 id="1-2-内存从哪里回收？"><a href="#1-2-内存从哪里回收？" class="headerlink" title="1.2 内存从哪里回收？"></a>1.2 内存从哪里回收？</h3><p>Redis占用的内存是分为两部分：<strong>存储键值对消耗和本身运行消耗</strong>。显然后者我们无法回收，因此只能从键值对下手了，键值对可以分为几种：<strong>带过期的、不带过期的、热点数据、冷数据</strong>。对于带过期的键值是需要删除的，如果删除了所有的过期键值对之后内存仍然不足怎么办？那只能把部分<strong>数据给踢掉</strong>了。</p>
<p><strong>人生无处不取舍</strong>，这个让笔者脑海浮现了《泰坦尼克》，邮轮撞到了冰山顷刻间海水涌入，面临数量不足的救生艇，人们做出了抉择：让女士和孩童先走，绅士们选择留下，海上逃生场景如图：<br><img src="https://img-blog.csdnimg.cn/20200727111541422.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200727111541423.png" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<h3 id="1-3-如何实施过期键值对的删除？"><a href="#1-3-如何实施过期键值对的删除？" class="headerlink" title="1.3 如何实施过期键值对的删除？"></a>1.3 如何实施过期键值对的删除？</h3><p>要实施对键值对的删除我们需要明白如下几点：</p>
<ul>
<li><p>带过期超时的键值对<strong>存储在哪里</strong>？</p>
</li>
<li><p>如何判断带超时的键值对<strong>是否可以被删除</strong>了？</p>
</li>
<li><p>删除机制<strong>有哪些</strong>以及<strong>如何选择</strong>？</p>
</li>
</ul>
<h4 id="1-3-1-键值对的存储"><a href="#1-3-1-键值对的存储" class="headerlink" title="1.3.1 键值对的存储"></a>1.3.1 键值对的存储</h4><p>老规矩来到github看下源码，src/server.h中给的redisDb结构体给出了答案：</p>
<div class="hljs"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisDb</span> &#123;</span>
    dict *dict;                 <span class="hljs-comment">/* The keyspace for this DB */</span>
    dict *expires;              <span class="hljs-comment">/* Timeout of keys with a timeout set */</span>
    dict *blocking_keys;        <span class="hljs-comment">/* Keys with clients waiting for data (BLPOP)*/</span>
    dict *ready_keys;           <span class="hljs-comment">/* Blocked keys that received a PUSH */</span>
    dict *watched_keys;         <span class="hljs-comment">/* WATCHED keys for MULTI/EXEC CAS */</span>
    <span class="hljs-keyword">int</span> id;                     <span class="hljs-comment">/* Database ID */</span>
    <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> avg_ttl;          <span class="hljs-comment">/* Average TTL, just for stats */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> expires_cursor; <span class="hljs-comment">/* Cursor of the active expire cycle. */</span>
    <span class="hljs-built_in">list</span> *defrag_later;         <span class="hljs-comment">/* List of key names to attempt to defrag one by one, gradually. */</span>
&#125; redisDb;</code></pre></div>
<p>Redis本质上就是一个大的key-value，key就是字符串，value有是几种对象：字符串、列表、有序列表、集合、哈希等，这些key-value都是<strong>存储在redisDb的dict中的</strong>，来看下黄健宏画的一张非常赞的图：</p>
<p><img src="https://img-blog.csdnimg.cn/20200727111750875.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>看到这里，对于删除机制又清晰了一步，我们只要把redisDb中dict中的目标key-value删掉就行，不过貌似没有这么简单，Redis对于过期键值对肯定有自己的组织规则，让我们继续研究吧！</p>
<p>redisDb的<code>expires</code>成员的类型也是dict，和键值对是一样的，本质上<code>expires是dict的子集</code>，expires保存的是所有带过期的键值对，称之为<code>过期字典</code>吧，它才是我们研究的重点。</p>
<p>对于键，我们可以设置<code>绝对和相对过期时间</code>、以及查看<code>剩余时间</code>：</p>
<ul>
<li><p>使用<code>EXPIRE和PEXPIRE</code>来实现键值对的秒级和毫秒级生存时间设定，这是<code>相对时长</code>的过期设置</p>
</li>
<li><p>使用<code>EXPIREAT和EXPIREAT</code>来实现键值对在某个秒级和毫秒级时间戳时进行过期删除，属于<code>绝对过期</code>设置</p>
</li>
<li><p>通过<code>TTL和PTTL</code>来查看带有生存时间的键值对的剩余过期时间</p>
</li>
</ul>
<p>上述三组命令在<code>设计缓存</code>用处比较大，有心的读者可以留意。</p>
<p>过期字典expires和键值对空间dict存储的内容并不完全一样，过期字典expires的key是指向Redis对应对象的指针，其value是long long型的<code>unix时间戳</code>，前面的EXPIRE和PEXPIRE相对时长最终也会转换为时间戳，来看下<code>过期字典expires的结构</code>，笔者画了个图：</p>
<p><img src="https://img-blog.csdnimg.cn/20200727111938129.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<h4 id="1-3-2-键值对的过期删除判断"><a href="#1-3-2-键值对的过期删除判断" class="headerlink" title="1.3.2 键值对的过期删除判断"></a>1.3.2 键值对的过期删除判断</h4><p>判断键是否过期可删除，需要先查<code>过期字典是否存在该值</code>，如果存在则进一步判断<code>过期时间戳</code>和<code>当前时间戳</code>的<code>相对大小</code>，做出删除判断，简单的流程如图：<br><img src="https://img-blog.csdnimg.cn/20200727112005301.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<h4 id="1-3-3-键值对的删除策略"><a href="#1-3-3-键值对的删除策略" class="headerlink" title="1.3.3 键值对的删除策略"></a>1.3.3 键值对的删除策略</h4><p>经过前面的几个环节，我们知道了Redis的两种存储位置：键空间和过期字典，以及过期字典expires的结构、判断是否过期的方法，那么该如何实施删除呢？</p>
<p>先抛开Redis来想一下可能的几种<code>删除策略</code>：</p>
<ul>
<li><p><code>定时删除</code>：在设置键的过期时间的同时，创建定时器，让定时器在键过期时间到来时，即刻执行键值对的删除；</p>
</li>
<li><p><code>定期删除</code>：每隔特定的时间对数据库进行一次扫描，检测并删除其中的过期键值对；</p>
</li>
<li><p><code>惰性删除</code>：键值对过期暂时不进行删除，至于删除的时机与键值对的使用有关，当获取键时先查看其是否过期，过期就删除，否则就保留；</p>
</li>
</ul>
<p>在上述的三种策略中定时删除和定期删除属于不同时间粒度的<code>主动删除</code>，惰性删除属于<code>被动删除</code>。</p>
<p>三种策略都有各自的优缺点：<code>定时删除</code>对内存使用率有优势，但是对<code>CPU不友好，惰性删除对内存不友好</code>，如果某些键值对一直不被使用，那么会造成一定量的内存浪费，<code>定期删除是定时删除和惰性删除的折中</code>。</p>
<p>Reids采用的是<code>惰性删除和定时删除的结合</code>，一般来说可以借助<code>最小堆</code>来实现定时器，不过Redis的设计考虑到时间事件的有限种类和数量，使用了<code>无序链表存储时间事件</code>，这样如果<code>在此基础上</code>实现定时删除，就意味着O(N)遍历获取最近需要删除的数据。</p>
<p>但是我觉得antirez如果非要使用定时删除，那么他<code>肯定不会使用原来的无序链表机制</code>，所以个人认为已存在的无序链表不能作为Redis不使用定时删除的<code>根本理由</code>，<code>冒昧猜测唯一可能</code>的是antirez觉得<code>没有必要</code>使用定时删除。</p>
<p><img src="https://img-blog.csdnimg.cn/202007271120587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzczNjgx,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<h4 id="1-3-4-定期删除的实现细节"><a href="#1-3-4-定期删除的实现细节" class="headerlink" title="1.3.4 定期删除的实现细节"></a>1.3.4 定期删除的实现细节</h4><p>定期删除听着很简单，但是如何控制执行的频率和时长呢？</p>
<p>试想一下如果执行<code>频率太少就退化为惰性删除</code>了，如果执行<code>时间太长又和定时删除类似</code>了，想想还确实是个难题！并且执行<code>定期删除的时机</code>也需要考虑，所以我们继续来看看Redis是如何实现定期删除的吧！笔者在<code>src/expire.c</code>文件中找到了<code>activeExpireCycle</code>函数，定期删除就是由此函数实现的，在代码中antirez做了比较详尽的注释，不过都是英文的，试着读了一下模模糊糊弄个大概，所以<code>学习英文并阅读外文资料是很重要的学习途径</code>。</p>
<p>先贴一下代码，核心部分算上注释<code>大约210行</code>，具体看下：</p>
<div class="hljs"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP 20 <span class="hljs-comment">/* Keys for each DB loop. */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> ACTIVE_EXPIRE_CYCLE_FAST_DURATION 1000 <span class="hljs-comment">/* Microseconds. */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 25 <span class="hljs-comment">/* Max % of CPU to use. */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE 10 <span class="hljs-comment">/* % of stale keys after which</span></span>
<span class="hljs-meta"><span class="hljs-comment">                                                   we do extra efforts. */</span></span>

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">activeExpireCycle</span><span class="hljs-params">(<span class="hljs-keyword">int</span> type)</span> </span>&#123;
    <span class="hljs-comment">/* Adjust the running parameters according to the configured expire</span>
<span class="hljs-comment">     * effort. The default effort is 1, and the maximum configurable effort</span>
<span class="hljs-comment">     * is 10. */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span>
    effort = server.active_expire_effort<span class="hljs-number">-1</span>, <span class="hljs-comment">/* Rescale from 0 to 9. */</span>
    config_keys_per_loop = ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP +
                           ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP/<span class="hljs-number">4</span>*effort,
    config_cycle_fast_duration = ACTIVE_EXPIRE_CYCLE_FAST_DURATION +
                                 ACTIVE_EXPIRE_CYCLE_FAST_DURATION/<span class="hljs-number">4</span>*effort,
    config_cycle_slow_time_perc = ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC +
                                  <span class="hljs-number">2</span>*effort,
    config_cycle_acceptable_stale = ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE-
                                    effort;

    <span class="hljs-comment">/* This function has some global state in order to continue the work</span>
<span class="hljs-comment">     * incrementally across calls. */</span>
    <span class="hljs-keyword">static</span> <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> current_db = <span class="hljs-number">0</span>; <span class="hljs-comment">/* Last DB tested. */</span>
    <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> timelimit_exit = <span class="hljs-number">0</span>;      <span class="hljs-comment">/* Time limit hit in previous call? */</span>
    <span class="hljs-keyword">static</span> <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> last_fast_cycle = <span class="hljs-number">0</span>; <span class="hljs-comment">/* When last fast cycle ran. */</span>

    <span class="hljs-keyword">int</span> j, iteration = <span class="hljs-number">0</span>;
    <span class="hljs-keyword">int</span> dbs_per_call = CRON_DBS_PER_CALL;
    <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> start = ustime(), timelimit, elapsed;

    <span class="hljs-comment">/* When clients are paused the dataset should be static not just from the</span>
<span class="hljs-comment">     * POV of clients not being able to write, but also from the POV of</span>
<span class="hljs-comment">     * expires and evictions of keys not being performed. */</span>
    <span class="hljs-keyword">if</span> (clientsArePaused()) <span class="hljs-keyword">return</span>;

    <span class="hljs-keyword">if</span> (type == ACTIVE_EXPIRE_CYCLE_FAST) &#123;
        <span class="hljs-comment">/* Don&#x27;t start a fast cycle if the previous cycle did not exit</span>
<span class="hljs-comment">         * for time limit, unless the percentage of estimated stale keys is</span>
<span class="hljs-comment">         * too high. Also never repeat a fast cycle for the same period</span>
<span class="hljs-comment">         * as the fast cycle total duration itself. */</span>
        <span class="hljs-keyword">if</span> (!timelimit_exit &amp;&amp;
            server.stat_expired_stale_perc &lt; config_cycle_acceptable_stale)
            <span class="hljs-keyword">return</span>;

        <span class="hljs-keyword">if</span> (start &lt; last_fast_cycle + (<span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span>)config_cycle_fast_duration*<span class="hljs-number">2</span>)
            <span class="hljs-keyword">return</span>;

        last_fast_cycle = start;
    &#125;

    <span class="hljs-comment">/* We usually should test CRON_DBS_PER_CALL per iteration, with</span>
<span class="hljs-comment">     * two exceptions:</span>
<span class="hljs-comment">     *</span>
<span class="hljs-comment">     * 1) Don&#x27;t test more DBs than we have.</span>
<span class="hljs-comment">     * 2) If last time we hit the time limit, we want to scan all DBs</span>
<span class="hljs-comment">     * in this iteration, as there is work to do in some DB and we don&#x27;t want</span>
<span class="hljs-comment">     * expired keys to use memory for too much time. */</span>
    <span class="hljs-keyword">if</span> (dbs_per_call &gt; server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    <span class="hljs-comment">/* We can use at max &#x27;config_cycle_slow_time_perc&#x27; percentage of CPU</span>
<span class="hljs-comment">     * time per iteration. Since this function gets called with a frequency of</span>
<span class="hljs-comment">     * server.hz times per second, the following is the max amount of</span>
<span class="hljs-comment">     * microseconds we can spend in this function. */</span>
    timelimit = config_cycle_slow_time_perc*<span class="hljs-number">1000000</span>/server.hz/<span class="hljs-number">100</span>;
    timelimit_exit = <span class="hljs-number">0</span>;
    <span class="hljs-keyword">if</span> (timelimit &lt;= <span class="hljs-number">0</span>) timelimit = <span class="hljs-number">1</span>;

    <span class="hljs-keyword">if</span> (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = config_cycle_fast_duration; <span class="hljs-comment">/* in microseconds. */</span>

    <span class="hljs-comment">/* Accumulate some global stats as we expire keys, to have some idea</span>
<span class="hljs-comment">     * about the number of keys that are already logically expired, but still</span>
<span class="hljs-comment">     * existing inside the database. */</span>
    <span class="hljs-keyword">long</span> total_sampled = <span class="hljs-number">0</span>;
    <span class="hljs-keyword">long</span> total_expired = <span class="hljs-number">0</span>;

    <span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; dbs_per_call &amp;&amp; timelimit_exit == <span class="hljs-number">0</span>; j++) &#123;
        <span class="hljs-comment">/* Expired and checked in a single loop. */</span>
        <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> expired, sampled;

        redisDb *db = server.db+(current_db % server.dbnum);

        <span class="hljs-comment">/* Increment the DB now so we are sure if we run out of time</span>
<span class="hljs-comment">         * in the current DB we&#x27;ll restart from the next. This allows to</span>
<span class="hljs-comment">         * distribute the time evenly across DBs. */</span>
        current_db++;

        <span class="hljs-comment">/* Continue to expire if at the end of the cycle more than 25%</span>
<span class="hljs-comment">         * of the keys were expired. */</span>
        <span class="hljs-keyword">do</span> &#123;
            <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> num, slots;
            <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> now, ttl_sum;
            <span class="hljs-keyword">int</span> ttl_samples;
            iteration++;

            <span class="hljs-comment">/* If there is nothing to expire try next DB ASAP. */</span>
            <span class="hljs-keyword">if</span> ((num = dictSize(db-&gt;expires)) == <span class="hljs-number">0</span>) &#123;
                db-&gt;avg_ttl = <span class="hljs-number">0</span>;
                <span class="hljs-keyword">break</span>;
            &#125;
            slots = dictSlots(db-&gt;expires);
            now = mstime();

            <span class="hljs-comment">/* When there are less than 1% filled slots, sampling the key</span>
<span class="hljs-comment">             * space is expensive, so stop here waiting for better times...</span>
<span class="hljs-comment">             * The dictionary will be resized asap. */</span>
            <span class="hljs-keyword">if</span> (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp;
                (num*<span class="hljs-number">100</span>/slots &lt; <span class="hljs-number">1</span>)) <span class="hljs-keyword">break</span>;

            <span class="hljs-comment">/* The main collection cycle. Sample random keys among keys</span>
<span class="hljs-comment">             * with an expire set, checking for expired ones. */</span>
            expired = <span class="hljs-number">0</span>;
            sampled = <span class="hljs-number">0</span>;
            ttl_sum = <span class="hljs-number">0</span>;
            ttl_samples = <span class="hljs-number">0</span>;

            <span class="hljs-keyword">if</span> (num &gt; config_keys_per_loop)
                num = config_keys_per_loop;

            <span class="hljs-comment">/* Here we access the low level representation of the hash table</span>
<span class="hljs-comment">             * for speed concerns: this makes this code coupled with dict.c,</span>
<span class="hljs-comment">             * but it hardly changed in ten years.</span>
<span class="hljs-comment">             *</span>
<span class="hljs-comment">             * Note that certain places of the hash table may be empty,</span>
<span class="hljs-comment">             * so we want also a stop condition about the number of</span>
<span class="hljs-comment">             * buckets that we scanned. However scanning for free buckets</span>
<span class="hljs-comment">             * is very fast: we are in the cache line scanning a sequential</span>
<span class="hljs-comment">             * array of NULL pointers, so we can scan a lot more buckets</span>
<span class="hljs-comment">             * than keys in the same time. */</span>
            <span class="hljs-keyword">long</span> max_buckets = num*<span class="hljs-number">20</span>;
            <span class="hljs-keyword">long</span> checked_buckets = <span class="hljs-number">0</span>;

            <span class="hljs-keyword">while</span> (sampled &lt; num &amp;&amp; checked_buckets &lt; max_buckets) &#123;
                <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> table = <span class="hljs-number">0</span>; table &lt; <span class="hljs-number">2</span>; table++) &#123;
                    <span class="hljs-keyword">if</span> (table == <span class="hljs-number">1</span> &amp;&amp; !dictIsRehashing(db-&gt;expires)) <span class="hljs-keyword">break</span>;

                    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> idx = db-&gt;expires_cursor;
                    idx &amp;= db-&gt;expires-&gt;ht[table].sizemask;
                    dictEntry *de = db-&gt;expires-&gt;ht[table].table[idx];
                    <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> ttl;

                    <span class="hljs-comment">/* Scan the current bucket of the current table. */</span>
                    checked_buckets++;
                    <span class="hljs-keyword">while</span>(de) &#123;
                        <span class="hljs-comment">/* Get the next entry now since this entry may get</span>
<span class="hljs-comment">                         * deleted. */</span>
                        dictEntry *e = de;
                        de = de-&gt;next;

                        ttl = dictGetSignedIntegerVal(e)-now;
                        <span class="hljs-keyword">if</span> (activeExpireCycleTryExpire(db,e,now)) expired++;
                        <span class="hljs-keyword">if</span> (ttl &gt; <span class="hljs-number">0</span>) &#123;
                            <span class="hljs-comment">/* We want the average TTL of keys yet</span>
<span class="hljs-comment">                             * not expired. */</span>
                            ttl_sum += ttl;
                            ttl_samples++;
                        &#125;
                        sampled++;
                    &#125;
                &#125;
                db-&gt;expires_cursor++;
            &#125;
            total_expired += expired;
            total_sampled += sampled;

            <span class="hljs-comment">/* Update the average TTL stats for this database. */</span>
            <span class="hljs-keyword">if</span> (ttl_samples) &#123;
                <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> avg_ttl = ttl_sum/ttl_samples;

                <span class="hljs-comment">/* Do a simple running average with a few samples.</span>
<span class="hljs-comment">                 * We just use the current estimate with a weight of 2%</span>
<span class="hljs-comment">                 * and the previous estimate with a weight of 98%. */</span>
                <span class="hljs-keyword">if</span> (db-&gt;avg_ttl == <span class="hljs-number">0</span>) db-&gt;avg_ttl = avg_ttl;
                db-&gt;avg_ttl = (db-&gt;avg_ttl/<span class="hljs-number">50</span>)*<span class="hljs-number">49</span> + (avg_ttl/<span class="hljs-number">50</span>);
            &#125;

            <span class="hljs-comment">/* We can&#x27;t block forever here even if there are many keys to</span>
<span class="hljs-comment">             * expire. So after a given amount of milliseconds return to the</span>
<span class="hljs-comment">             * caller waiting for the other active expire cycle. */</span>
            <span class="hljs-keyword">if</span> ((iteration &amp; <span class="hljs-number">0xf</span>) == <span class="hljs-number">0</span>) &#123; <span class="hljs-comment">/* check once every 16 iterations. */</span>
                elapsed = ustime()-start;
                <span class="hljs-keyword">if</span> (elapsed &gt; timelimit) &#123;
                    timelimit_exit = <span class="hljs-number">1</span>;
                    server.stat_expired_time_cap_reached_count++;
                    <span class="hljs-keyword">break</span>;
                &#125;
            &#125;
            <span class="hljs-comment">/* We don&#x27;t repeat the cycle for the current database if there are</span>
<span class="hljs-comment">             * an acceptable amount of stale keys (logically expired but yet</span>
<span class="hljs-comment">             * not reclained). */</span>
        &#125; <span class="hljs-keyword">while</span> ((expired*<span class="hljs-number">100</span>/sampled) &gt; config_cycle_acceptable_stale);
    &#125;

    elapsed = ustime()-start;
    server.stat_expire_cycle_time_used += elapsed;
    latencyAddSampleIfNeeded(<span class="hljs-string">&quot;expire-cycle&quot;</span>,elapsed/<span class="hljs-number">1000</span>);

    <span class="hljs-comment">/* Update our estimate of keys existing but yet to be expired.</span>
<span class="hljs-comment">     * Running average with this sample accounting for 5%. */</span>
    <span class="hljs-keyword">double</span> current_perc;
    <span class="hljs-keyword">if</span> (total_sampled) &#123;
        current_perc = (<span class="hljs-keyword">double</span>)total_expired/total_sampled;
    &#125; <span class="hljs-keyword">else</span>
        current_perc = <span class="hljs-number">0</span>;
    server.stat_expired_stale_perc = (current_perc*<span class="hljs-number">0.05</span>)+
                                     (server.stat_expired_stale_perc*<span class="hljs-number">0.95</span>);
&#125;</code></pre></div>
<p>说实话这个代码<code>细节比较多</code>，由于笔者对Redis源码<code>了解不多</code>，只能做个<code>模糊版本的解读</code>，所以难免有问题，还是建议有条件的读者自行前往源码区阅读，抛砖引玉看下笔者的模糊版本：</p>
<ul>
<li><p>该算法是个<strong>自适应的过程</strong>，当过期的key比较少时那么就花费很少的cpu时间来处理，如果过期的key很多就采用激进的方式来处理，避免大量的内存消耗，可以理解为判断过期键<code>多就多跑几次，少则少跑几次</code>；</p>
</li>
<li><p>由于Redis中有很多数据库db，该算法会逐个扫描，本次结束时继续向后面的db扫描，是个<strong>闭环的过程</strong>；</p>
</li>
<li><p>定期删除有<strong>快速循环和慢速循环两种模式</strong>，主要采用慢速循环模式，其循环频率主要取决于server.hz，通常设置为10，也就是每秒执行10次慢循环定期删除，执行过程中如果耗时超过25%的CPU时间就停止；</p>
</li>
<li><p>慢速循环的执行时间相对较长，会出现超时问题，快速循环模式的执行时间<strong>不超过1ms</strong>，也就是执行<strong>时间更短</strong>，但是执行的<strong>次数更多</strong>，在执行过程中发现某个db中<strong>抽样的key</strong>中过期key占比**低于25%**则跳过；</p>
</li>
</ul>
<p>主体意思：定期删除是个<code>自适应的闭环并且概率化的抽样扫描过程</code>，过程中都有执行时间和cpu时间的限制，如果触发阈值就停止，可以说是尽量在不影响对客户端的响应下<code>润物细无声</code>地进行的。</p>
<h4 id="1-3-5-DEL删除键值对"><a href="#1-3-5-DEL删除键值对" class="headerlink" title="1.3.5 DEL删除键值对"></a>1.3.5 DEL删除键值对</h4><p>在Redis4.0之前执行del操作时如果key-value很大，那么可能导致阻塞，在新版本中引入了BIO线程以及一些新的命令，实现了del的延时懒删除，最后会有<code>BIO线程</code>来实现内存的清理回收。</p>
<p>之前写过一篇4.0版本的LazyFree相关的文章，可以看下<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMTI2Ng==&mid=2247483717&idx=1&sn=dfa5cafa7695f2d0dfb8bc51b414d46b&scene=21#wechat_redirect">浅析Redis 4.0新特性之LazyFree</a></p>
<h3 id="1-4-内存淘汰机制"><a href="#1-4-内存淘汰机制" class="headerlink" title="1.4 内存淘汰机制"></a>1.4 内存淘汰机制</h3><p>为了保证Redis的安全稳定运行，设置了一个max-memory的阈值，那么当内存用量到达阈值，新写入的键值对无法写入，此时就需要内存淘汰机制，在Redis的配置中有几种<code>淘汰策略</code>可以选择，详细如下：</p>
<ul>
<li><p>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错；</p>
</li>
<li><p>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中移除最近最少使用的 key；</p>
</li>
<li><p>allkeys-random：当内存不足以容纳新写入数据时，在键空间中随机移除某个 key；</p>
</li>
<li><p>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key；</p>
</li>
<li><p>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key；</p>
</li>
<li><p>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除；</p>
</li>
</ul>
<p>后三种策略都是针对过期字典的处理，但是在过期字典为空时会noeviction一样返回写入失败，毫无策略地随机删除也不太可取，所以一般选择第二种allkeys-lru基于LRU策略进行淘汰。</p>
<p>个人认为antirez一向都是<code>工程化思维</code>，善于使用<code>概率化设计</code>来做近似实现，LRU算法也不例外，Redis中实现了<code>近似LRU算法</code>，并且经过几个版本的迭代效果已经比较接近理论LRU算法的效果了，这个也是个不错的内容，由于篇幅限制，本文计划后续单独讲LRU算法时再进行详细讨论。</p>
<h3 id="1-5-过期键删除和内存淘汰的关系"><a href="#1-5-过期键删除和内存淘汰的关系" class="headerlink" title="1.5 过期键删除和内存淘汰的关系"></a>1.5 过期键删除和内存淘汰的关系</h3><p><code>过期健删除</code>策略<code>强调</code>的是<code>对过期健的操作</code>，如果有健过期而内存足够，Redis不会使用内存淘汰机制来腾退空间，这时会优先使用过期健删除策略删除过期健。</p>
<p><code>内存淘汰</code>机制<code>强调</code>的是<code>对内存数据的淘汰操作</code>，当内存不足时，即使有的健没有到达过期时间或者根本没有设置过期也要根据一定的策略来删除一部分，腾退空间保证新数据的写入。</p>
<h2 id="Q7-讲讲你对Redis持久化机制的理解。"><a href="#Q7-讲讲你对Redis持久化机制的理解。" class="headerlink" title="Q7:讲讲你对Redis持久化机制的理解。"></a>Q7:讲讲你对Redis持久化机制的理解。</h2><p>个人认为Redis持久化既是数据库本身的亮点，也是面试的热点，主要考察的方向包括：<code>RDB机制原理、AOF机制原理、各自的优缺点、工程上的对于RDB和AOF的取舍、新版本Redis混合持久化策略</code>等，如能把握要点，持久化问题就过关了。</p>
<p>之前写过一篇持久化的文章：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMTI2Ng==&mid=2247483700&idx=1&sn=a935b0320f9daaa3d0102c8a6095fad7&scene=21#wechat_redirect">理解Redis持久化</a>,基本上也涵盖了上面的几个点，可以看一下。</p>
<h2 id="Q8-谈谈你对Redis数据同步-复制-的理解吧！"><a href="#Q8-谈谈你对Redis数据同步-复制-的理解吧！" class="headerlink" title="Q8:谈谈你对Redis数据同步(复制)的理解吧！"></a>Q8:谈谈你对Redis数据同步(复制)的理解吧！</h2><p><strong>持久化和数据同步的关系</strong></p>
<p>理解持久化和数据同步的关系，需要从<code>单点故障</code>和<code>高可用</code>两个角度来分析：</p>
<p><strong>单点宕机故障</strong></p>
<p>假如我们现在只有一台作为缓存的Redis机器，通过持久化将热点数据写到磁盘，某时刻该Redis单点机器发生<code>故障宕机</code>，此期间缓存失效，<code>主存储服务</code>将承受所有的请求<code>压力倍增</code>，监控程序将宕机Redis<code>机器拉起</code>。</p>
<p>重启之后，该机器可以Load磁盘RDB数据进行<code>快速恢复</code>，恢复的时间取决于数据量的多少，一般秒级到分钟级不等，恢复完成保证之前的热点数据还在，这样存储系统的CacheMiss就会降低，有效降低了<code>缓存击穿</code>的影响。</p>
<p>在单点Redis中持久化机制非常有用，<strong>只写文字容易让大家睡着</strong>，我画了张图：<br><img src="https://img-blog.csdnimg.cn/20200727113432922.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p><strong>高可用的Redis系统</strong></p>
<p>作为一个<code>高可用</code>的缓存系统单点宕机是不允许的，因此就出现了<code>主从架构</code>，对主节点的数据进行<code>多个备份</code>，如果主节点挂点，可以立刻切换<code>状态最好</code>的从节点为主节点，对外提供写服务，并且其他从节点向新主节点同步数据，确保整个Redis缓存系统的高可用。</p>
<p>如图展示了一个<code>一主两从读写分离的Redis系统</code>主节点<code>故障迁移</code>的过程，整个过程并没有停止<code>正常工作</code>，大大提高了系统的高可用：<br><img src="https://img-blog.csdnimg.cn/20200727113536941.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>从上面的两点分析可以得出个小结论<strong>划重点</strong>：<br><strong>持久化让单点故障不再可怕，数据同步为高可用插上翅膀。</strong></p>
<p>我们理解了数据同步对Redis的重要作用，接下来继续看数据同步的实现原理和过程、重难点等细节问题吧！</p>
<p><strong>Redis系统中的CAP理论</strong></p>
<p>对分布式存储有了解的读者一定知道<code>CAP理论</code>，说来惭愧笔者在2018年3月份换工作的时候，去Face++旷视科技面后端开发岗位时就遇到了CAP理论，除了CAP理论问题之外其他问题都在射程内，所以最终还是拿了Offer。</p>
<p>但是印象很深T大毕业的面试官说前面的问题答得都不错，为啥CAP问题答得这么菜…其实我当时只知道CAP理论就像高富帅一样，不那么容易达到…细节不清楚…</p>
<p>各位吃瓜读者，笔者前面说这个小事情的目的是想表达：<code>CAP理论对于理解分布式存储非常重要</code>，下回你们面试被问到CAP别怪我没提醒。</p>
<p>在理论计算机科学中，CAP定理又被称作<code>布鲁尔定理Brewer&#39;s theorem</code>，这个定理起源于加州大学<code>伯克利分校</code>的计算机科学家埃里克·布鲁尔在2000年的分布式计算原理研讨会<code>PODC</code>上提出的一个<code>猜想</code>。</p>
<p>在2002年<code>麻省理工学院</code>的赛斯·吉尔伯特和南希·林奇发表了<code>布鲁尔猜想的证明</code>，使之成为一个<code>定理。</code>它指出对于一个分布式计算系统来说，不可能同时满足以下三点：</p>
<ul>
<li><p>C Consistent 一致性 连贯性</p>
</li>
<li><p>A Availability 可用性</p>
</li>
<li><p>P Partition Tolerance 分区容忍性</p>
</li>
</ul>
<p>来看一张<code>阮一峰大佬画的图</code>：</p>
<p><img src="https://img-blog.csdnimg.cn/20200727113811395.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>举个简单的例子，说明一下CP和AP的兼容性：</p>
<p><strong>CP和AP问题</strong></p>
<p>理解CP和AP的关键在于分区容忍性P，网络分区在分布式存储中再平常不过了，即使机器在一个机房，也不可能全都在一个机架或一台交换机。</p>
<p>这样在局域网就会出现<code>网络抖动</code>，笔者做过1年多DPI对于网络传输中最深刻的三个名词：<code>丢包、乱序、重传</code>。所以<code>我们看来风平浪静的网络，在服务器来说可能是风大浪急</code>，一不小心就不通了，所以当网络出现断开时，这时就出现了网络分区问题。</p>
<p>对于Redis数据同步而言，假设从结点和主结点在两个机架上，某时刻发生网络断开，如果此时Redis读写分离，那么从结点的数据必然无法与主继续同步数据。在这种情况下，如果<code>继续在从结点读取数据就造成数据不一致问题，如果强制保证数据一致从结点就无法提供服务造成不可用问题</code>，从而看出在<code>P的影响下C和A无法兼顾</code>。<br>其他几种情况就不深入了，从上面我们可以得出结论：<code>当Redis多台机器分布在不同的网络中，如果出现网络故障，那么数据一致性和服务可用性无法兼顾，Redis系统对此必须做出选择，事实上Redis选择了可用性，或者说Redis选择了另外一种最终一致性。</code></p>
<p><strong>最终一致性</strong></p>
<p>Redis选择了<code>最终一致性</code>，也就是<code>不保证</code>主从数据在<code>任何时刻</code>都是<code>一致</code>的，并且Redis主从同步默认是<code>异步</code>的，亲爱的盆友们<code>不要晕！不要蒙圈！</code></p>
<p>我来一下解释<code>同步复制和异步复制</code>(注意：<code>考虑读者的感受 我并没有写成同步同步和异步同步 哈哈</code>)：</p>
<p><img src="https://img-blog.csdnimg.cn/2020072711403179.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>一图胜千言，看红色的数字就知道<code>同步复制和异步复制</code>的区别了：</p>
<ul>
<li><p><strong>异步复制</strong>：当客户端向主结点写了hello world，主节点写成功之后就向客户端回复OK，这样主节点和客户端的交互就完成了，之后主节点向从结点同步hello world，从结点完成之后向主节点回复OK，整个过程客户端不需要等待从结点同步完成，因此整个过程是异步实现的。</p>
</li>
<li><p><strong>同步复制</strong>：当客户端向主结点写了hello world，主节点向从结点同步hello world，从结点完成之后向主节点回复OK，之后主节点向客户端回复OK，整个过程客户端需要等待从结点同步完成，因此整个过程是同步实现的。</p>
</li>
</ul>
<p>Redis选择异步复制可以避免客户端的等待，更符合现实要求，不过这个复制方式可以修改，根据自己需求而定吧。</p>
<p><strong>从从复制</strong></p>
<p>假如Redis高可用系统中有<code>一主四从</code>，如果四个从同时向主节点进行数据同步，主节点的压力会比较大，考虑到Redis的最终一致性，因此Redis后续推出了<code>从从复制</code>，从而将<code>单层复制结构演进为多层复制结构</code>，笔者画了个图看下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200727114219285.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br><strong>全量复制和增量复制</strong></p>
<p><code>全量复制</code>是从结点因为故障恢复或者新添加从结点时出现的<code>初始化阶段</code>的数据复制，这种复制是将主节点的数据全部同步到从结点来完成的，所以成本大但又不可避免。</p>
<p><code>增量复制</code>是主从结点正常工作之后的每个时刻进行的数据复制方式，<code>涓涓细流同步数据</code>，这种同步方式又轻又快，优点确实不少，不过如果没有全量复制打下基础增量复制也没戏，所以二者不是矛盾存在而是<code>相互依存</code>的。</p>
<p><img src="https://img-blog.csdnimg.cn/20200727114305569.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p><strong>全量复制过程分析</strong></p>
<p>Redis的全量复制过程主要分<strong>三个阶段</strong>：</p>
<ul>
<li><p><strong>快照阶段</strong>：从结点向主结点发起SYNC全量复制命令，主节点执行bgsave将内存中全部数据生成快照并发送给从结点，从结点释放旧内存载入并解析新快照，主节点同时将此阶段所产生的新的写命令存储到缓冲区。</p>
</li>
<li><p><strong>缓冲阶段</strong>：主节点向从节点同步存储在缓冲区的操作命令，这部分命令主节点是bgsave之后到从结点载入快照这个时间段内的新增命令，需要记录要不然就出现数据丢失。</p>
</li>
</ul>
<p>增量阶段：缓冲区同步完成之后，主节点正常向从结点同步增量操作命令，至此主从保持基本一致的步调。</p>
<p>借鉴参考1的一张图表，写的很好，我就不再重复画图了：</p>
<p>考虑一个<code>多从并发全量复制问题</code>：<br><strong>如果此时有多个从结点同时向主结点发起全量同步请求会怎样？</strong><br>Redis主结点是个<strong>聪明又诚实</strong>的家伙，比如现在有3个从结点A/B/C陆续向主节点发起SYNC全量同步请求。</p>
<ul>
<li>主节点在对A进行bgsave的同时，B和C的SYNC命令到来了，那么主节点就一锅烩，把针对A的快照数据和缓冲区数据同时同步给ABC，这样提高了效率又保证了正确性。</li>
<li>主节点对A的快照已经完成并且现在正在进行缓冲区同步，那么只能等A完成之后，再对B和C进行和A一样的操作过程，来实现新节点的全量同步，所以主节点并没有偷懒而是重复了这个过程，虽然繁琐但是保证了正确性。</li>
</ul>
<p>再考虑一个<code>快照复制循环问题</code>：<br>主节点执行bgsave是<code>比较耗时且耗内存的操作</code>，期间从结点也经历<code>装载旧数据-&gt;释放内存-&gt;装载新数据`的过程，</code>内存先升后降再升的动态过程<code>，从而知道无论主节点执行快照还是从结点装载数据都是需要</code>时间和资源``的。</p>
<p>抛开对性能的影响，试想如果主节点快照时间是1分钟，在期间有<code>1w条新命令</code>到来，这些新命令都将写到缓冲区，如果<code>缓冲区比较小只有8k</code>，那么在快照完成之后，<code>主节点缓冲区也只有8k命令丢失了2k命令</code>，那么此时从结点进行全量同步就缺失了数据，是一次错误的全量同步。</p>
<p>无奈之下，<code>从结点会再次发起SYNC命令</code>，从而<code>陷入循环</code>，因此<code>缓冲区大小</code>的设置很重要，二话不说再来一张图：<br><img src="https://img-blog.csdnimg.cn/20200727114724251.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p><strong>增量复制过程分析</strong></p>
<p>增量复制过程稍微简单一些，但是非常有用，试想<code>复杂的网络环境下，并不是每次断开都无法恢复，如果每次断开恢复后就要进行全量复制，那岂不是要把主节点搞死</code>，所以增量复制算是对复杂网络环境下数据复制过程的一个优化，允许一段时间的落后，最终追上就行。</p>
<p>增量复制是个<code>典型的生产者-消费者模型</code>，使用定长环形数组(队列)来实现，如果buffer满了那么新数据将覆盖老数据，因此从结点在复制数据的同时向主节点反馈自己的偏移量，从而确保数据不缺失。</p>
<p>这个过程非常好理解，<code>kakfa这种MQ也是这样的</code>，所以在合理设置buffer大小的前提下，理论上从的消费能力是大于主的生产能力的，大部分只有在网络断开时间过长时会出现buffer被覆盖，从结点消费滞后的情况，此时只能进行全量复制了。<br><img src="https://img-blog.csdnimg.cn/20200727114804630.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p><strong>无盘复制</strong></p>
<p><strong>理解无盘复制之前先看下什么是有盘复制呢？</strong><br>所谓盘是指磁盘，可能是机械磁盘或者SSD，但是无论哪一种相比内存都更慢，我们都知道IO操作在服务端的耗时是占大头的，因此对于全量复制这种高IO耗时的操作来说，尤其当服务并发比较大且还在进行其他操作时对Redis服务本身的影响是比较大大，之前的模式时这样的：<br><img src="https://img-blog.csdnimg.cn/20200727115014794.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p>在Redis2.8.18版本之后，开发了<strong>无盘复制</strong>，也就是<strong>避免了生成的RDB文件落盘再加载再网络传输的过程，而是流式的遍历发送过程，主节点一边遍历内存数据，一边将数据序列化发送给从结点</strong>，从结点没有变化，仍然将数据依次存储到本地磁盘，完成传输之后进行内存加载，<strong>可见无盘复制是对IO更友好</strong>。</p>
<p><strong>小结</strong></p>
<p>时间原因只能写这么多了，<code>和大家一起学习不是把桶填满而是把火点燃。</code></p>
<p><strong>回顾一下</strong>：本文主要讲述了持久化和数据同步的关系、Redis分布式存储的CAP选择、Redis数据同步复制和异步复制、全量复制和增量复制的原理、无盘复制等，相信耐心的读者一定会有所收获的。</p>
<p><strong>最后可以思考一个问题</strong>：<br>Redis的<code>数据同步仍然会出现数据丢失的情况</code>，比如主节点往缓冲区写了10k条操作命令，此时主挂掉了，从结点只消费了9k操作命令，那么切主之后从结点的数据就丢失了1k，即使旧主节点恢复也只能作为从节点向新主节点发起全量复制，那么我们该如何优化这种情况呢？</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Redis/">Redis</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Redis/">Redis</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/09/09/linux-deploy-project-war/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Linux中以 Jar 包的方式部署SpringBoot项目</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/09/08/docker-deploy-proejct/">
                        <span class="hidden-mobile">docker部署项目（jar包和war包）</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <script type="text/javascript">
    function loadUtterances() {
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'ifknow/utteranc-blog');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', 'github-light');
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    }
    waitElementVisible('comments', loadUtterances)
  </script>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->

  <div class="col-lg-7 mx-auto nopadding-md">
    <div class="container custom post-content mx-auto">
      <img src="https://gulimall-gsy.oss-cn-hangzhou.aliyuncs.com/blog/title/jetpacktocat.png" srcset="/img/loading.gif" class="rounded mx-auto d-block mt-5" style="width:150px; height:150px;">
    </div>
  </div>


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


    
  <!-- 备案信息 -->
  <div class="beian">
    <a href="http://beian.miit.gov.cn/" target="_blank"
       rel="nofollow noopener">豫ICP备20019433号</a>
    
  </div>


    

    <div>
      <span id="timeDate">载入天数...</span>
      <span id="times">载入时分秒...</span>
      <script>
        var now = new Date();
        function createtime() {
          var grt = new Date("08/25/2020 00:00:00");//此处修改你的建站时间或者网站上线时间
          now.setTime(now.getTime() + 250);
          days = (now - grt) / 1000 / 60 / 60 / 24;
          dnum = Math.floor(days);
          hours = (now - grt) / 1000 / 60 / 60 - (24 * dnum);
          hnum = Math.floor(hours);
          if (String(hnum).length == 1) {
            hnum = "0" + hnum;
          }
          minutes = (now - grt) / 1000 / 60 - (24 * 60 * dnum) - (60 * hnum);
          mnum = Math.floor(minutes);
          if (String(mnum).length == 1) {
            mnum = "0" + mnum;
          }
          seconds = (now - grt) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
          snum = Math.round(seconds);
          if (String(snum).length == 1) {
            snum = "0" + snum;
          }
          document.getElementById("timeDate").innerHTML = "本站安全运行&nbsp" + dnum + "&nbsp天";
          document.getElementById("times").innerHTML = hnum + "&nbsp小时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
        }
        setInterval("createtime()", 250);
      </script>
    </div>
    <p id="hitokoto" style="font-size:0.85rem">:D 获取中...</p>
    <script>
      fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
          const hitokoto = document.getElementById('hitokoto')
          hitokoto.innerText = data.hitokoto
        })
        .catch(console.error)
    </script>
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer>
  (function () {
    // 查询存储的记录
    function getRecord(Counter, target) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({target})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {target, time: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    }

    // 发起自增请求
    function increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    }

    // 构建自增请求体
    function buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "time": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    }

    // 校验是否为有效的 UV
    function validUV() {
      var key = 'LeanCloud_UV_Flag';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    }

    function addCount(Counter) {
      var enableIncr = 'true' === 'true' && window.location.hostname !== 'localhost';
      var getterArr = [];
      var incrArr = [];

      // 请求 PV 并自增
      var pvCtn = document.querySelector('#leancloud-site-pv-container');
      if (pvCtn || enableIncr) {
        var pvGetter = getRecord(Counter, 'site-pv').then((record) => {
          incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-pv');
          if (ele) {
            ele.innerText = record.time + 1;
            if (pvCtn) {
              pvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#leancloud-site-uv-container');
      if (uvCtn || enableIncr) {
        var uvGetter = getRecord(Counter, 'site-uv').then((record) => {
          var vuv = validUV();
          vuv && incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-uv');
          if (ele) {
            ele.innerText = record.time + (vuv ? 1 : 0);
            if (uvCtn) {
              uvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(uvGetter);
      }

      // 如果是文章，请求文章的浏览数，并自增
      if ('true' === 'true') {
        var viewCtn = document.querySelector('#leancloud-post-views-container');
        if (viewCtn || enableIncr) {
          var target = decodeURI('/2020/09/09/redis-interview/');
          var viewGetter = getRecord(Counter, target).then((record) => {
            incrArr.push(buildIncrement(record.objectId))
            if (viewCtn) {
              var ele = document.querySelector('#leancloud-post-views');
              if (ele) {
                ele.innerText = (record.time || 0) + 1;
                viewCtn.style.display = 'inline';
              }
            }
          });
          getterArr.push(viewGetter);
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && increment(Counter, incrArr);
        })
      }
    }

    var app_id = 'zrFnMoI7L8dVYCUGfmBTmFkG-gzGzoHsz'
    var app_key = '7h1obI3txkWKjMpE6uzmBpGG'
    var server_url = 'https://zrfnmoi7.lc-cn-n1-shared.com'

    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': app_id,
            'X-LC-Key': app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };

      addCount(Counter);
    }

    var api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${ app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(resp => resp.json())
        .then(({api_server}) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>






  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 6,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Redis面试全攻略、面试题大集合&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 50,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "left",
      visible: "hover",
      
      icon: "§"
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>







  
  
    <script type="text/javascript">
      //定义获取词语下标
      var a_idx = 0;
      jQuery(document).ready(function ($) {
        //点击body时触发事件
        $("body").click(function (e) {
          //需要显示的词语
          var a = new Array("富强", "民主", "文明", "和谐", "自由", "平等", "公正", "法治", "爱国", "敬业", "诚信", "友善");
          //设置词语给span标签
          var $i = $("<span/>").text(a[a_idx]);
          //下标等于原来下标+1  余 词语总数
          a_idx = (a_idx + 1) % a.length;
          //获取鼠标指针的位置，分别相对于文档的左和右边缘。
          //获取x和y的指针坐标
          var x = e.pageX, y = e.pageY;
          //在鼠标的指针的位置给$i定义的span标签添加css样式
          $i.css({
            "z-index": 999,
            "top": y - 20,
            "left": x,
            "position": "absolute",
            "font-weight": "bold",
            "color": rand_color()
          });
          // 随机颜色
          function rand_color() {
            return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
          }
          //在body添加这个标签
          $("body").append($i);
          //animate() 方法执行 CSS 属性集的自定义动画。
          //该方法通过CSS样式将元素从一个状态改变为另一个状态。CSS属性值是逐渐改变的，这样就可以创建动画效果。
          //详情请看http://www.w3school.com.cn/jquery/effect_animate.asp
          $i.animate({
            //将原来的位置向上移动180
            "top": y - 180,
            "opacity": 0
            //1500动画的速度
          }, 1500, function () {
            //时间到了自动删除
            $i.remove();
          });
        });
      })
      ;
    </script>
  











  

  

  

  

  

  




</body>
</html>
